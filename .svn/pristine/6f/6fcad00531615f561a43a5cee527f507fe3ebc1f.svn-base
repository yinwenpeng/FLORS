classdef Tagger < handle
    properties (SetAccess = private)
        parser
        map
        unlabeledData
        trainingData
        wordFeatures
    end
    
    methods
        % Creates a new tagger from a file
        function instance = Tagger(unlabeledData, trainingData, wordFeatures)
            instance.unlabeledData = unlabeledData;
            instance.trainingData = trainingData;
            
            % Instantiate classes for each type of feature
            instance.wordFeatures = javaArray ('nlp.processing.Features', length(wordFeatures));
            for i=1:length(wordFeatures)
                instance.wordFeatures(i) = eval(wordFeatures{i}.type);
                instance.wordFeatures(i).setAlwaysActive(wordFeatures{i}.alwaysActive);
            end
        end
        
        % Gets the feature vectors and labels of the training set
        function [features, labels, tokens] = getTrainingSet(instance, n, no_of_ngrams)
            gramGen = nlp.processing.NgramGenerator(instance.trainingData, false);
            if (strcmp('all',no_of_ngrams))
                no_of_ngrams = gramGen.getTotalNoOfNgrams();
            end
         
            [rawFeatures, features] = instance.getFeatures(gramGen, n, no_of_ngrams);
            
            instance.generateTagIds(rawFeatures.tags);
            labels = instance.mapTagsToLabels(rawFeatures.tags);
            tokens = rawFeatures.ngrams;
        end
        
        % Gets the feature vecotrs and labels of the test set
        function [features, labels, tokens, unknownTokens, sBoundaries] = getTestSet(instance, n, no_of_ngrams, testData)
            gramGen = nlp.processing.NgramGenerator(testData, false);
            if (strcmp('all',no_of_ngrams))
                no_of_ngrams = gramGen.getTotalNoOfNgrams();
            end
            [rawFeatures, features] = instance.getFeatures(gramGen, n, no_of_ngrams);
            
            labels = instance.mapTagsToLabels(rawFeatures.tags);
            tokens = rawFeatures.tokens;
            sBoundaries = rawFeatures.sentenceBoundaries.elements();
            unknownWords = testData.getUnknownWords(instance.trainingData);
            unknownTokens = ismember(cell(tokens), cell(unknownWords.toArray()));
        end
         
        % Gets the feature vectors given a nGram drawing instance
        function [rawFeatures, features] = getFeatures(instance, gramGen, n, no_of_ngrams)
            rawFeatures = gramGen.getFeatures(no_of_ngrams,instance.wordFeatures, n);
            
            features = Tagger.convertToMatlabMatrix(rawFeatures);
            features = Tagger.consolidateFeatures(features);
        end
        
        % Create a mapping between internal integer labels and POS tags
        function [] = generateTagIds(instance, rawTags)
            tags = cell(rawTags);
            allTags = unique(tags);
            instance.map.tagToId = containers.Map(allTags,1:length(allTags));
            instance.map.idToTag = containers.Map(1:length(allTags),allTags);
        end
  
        function [map] = getLabelsToTagMap(instance)
            map=instance.map.idToTag;
        end
    end
    
    methods (Access = private)
        % Maps a text tag to an internal integer label (for classification)
        function [labels] = mapTagsToLabels(instance,tags)
            tags=cell(tags);
            labels = zeros(length(tags),1);
            map=instance.map.tagToId;
            for i=1:length(tags)
                if map.isKey(tags{i})
                    labels(i,1)=map(tags{i});
                else
                    labels(i,1)=max(cell2mat(map.values)) + 1;
                end
            end
        end
    end
    methods (Static)
        % Normalizes each row of a matrix to have length 1
        function [ M ] = normRows( M )
            M = spdiags(spfun(@(x) 1./x,sqrt(sum(M.^2,2))),0,size(M,1), size(M,1))*M;
        end
        
         % Applies TF-Scaling to each non-zero entry
        function [ M ] = logScale( M )
            M = spfun(@(x) log(x) + 1, M);
        end
        
        % Converts the Java feature data to a sparse Matlab matrix
        function [features] = convertToMatlabMatrix(featuresTmp)
            no_of_ngrams = length(featuresTmp.ngrams);
            
            for j=1:length(featuresTmp.values)
                indicesX = double(featuresTmp.indicesX(j).elements());
                indicesY = double(featuresTmp.indicesY(j).elements());
                features.values{j}= sparse(indicesX, indicesY,...
                    double(featuresTmp.values(j).elements()),...
                    no_of_ngrams, length(featuresTmp.featureNames(j)));
                features.names{j} =  featuresTmp.featureNames(j);
            end
        end
        
        % Concatenates all single feature vectors to one large vector.
        % Logscales and normalizes each single feature vector before
        % appending it.
        function [features] = consolidateFeatures(singleFeatures)
            features.values = [];
            features.names = {};
            for i=1:length(singleFeatures.values)
                features.values = [features.values Tagger.normRows(Tagger.logScale(singleFeatures.values{i}))];
                features.names = [features.names singleFeatures.names{i}];
            end
        end
        
        % Prints out a feature vector for debugging
        function [] = printFeatureVector(features, tokens, index)
            indices =  find(features.values(index,:));
            fprintf('Feature\tValue\t\n');
            for nonzeroValue=indices
                fprintf('%s\t%.4f\n',char(features.names(nonzeroValue)),full(features.values(index,nonzeroValue)));
            end
            fprintf('Input n-gram: %s\n',char(tokens(index)));
        end
        
        % Returns the percentage of tokens that have the majority tag
        function [acc] = majBaseline(labels)
            acc = sum(labels == mode(labels))/length(labels);
        end
        
        % Maps a integer label (used for classification) to a POS tag name
        % (used for evaluation)
        function [tags] = mapLabelsToTags(map,labels)
            tags = cell(length(labels),1);
            
            for i=1:length(labels)
                if map.isKey(labels(i))
                    tags{i,1}=map(labels(i));
                else
                    tags{i,1} = 'UNKNOWN';
                end
            end
        end
        
        % Creates a summary of all errors and writes the results out to a
        % file
        function [] = printErrors(map, labelsGold, labelsPredicted, oovIndices, tokens, file, sentenceBoundaries)
            errorsOn = (labelsGold~= labelsPredicted) & oovIndices;
            
            fprintf('gold tag\terrors\ttotal\trel. errors\tclass recall\tclass precision\n');
            errorStatistics = sortrows(tabulate(labelsGold(errorsOn)),-2);
            errorNames = Tagger.mapLabelsToTags(map, errorStatistics(:,1));
            for i=1:length(errorStatistics)
                classSize = sum(labelsGold(oovIndices) == errorStatistics(i,1));
                taggedAs = sum(labelsPredicted(oovIndices) == errorStatistics(i,1));
                taggedAsCorrectly = sum((labelsPredicted(oovIndices) == errorStatistics(i,1)) & (labelsPredicted(oovIndices) == labelsGold(oovIndices)));
                precision = taggedAsCorrectly*100/taggedAs;
                fprintf('%s\t%d\t%d\t%.1f%%\t%.1f%%\t%.1f%%\n',errorNames{i},errorStatistics(i,2),classSize,errorStatistics(i,2)*100/sum(oovIndices), (1-errorStatistics(i,2)/classSize)*100, precision);
            end
            fprintf('\n');
            
            fid = fopen(file,'w');
            gold = Tagger.mapLabelsToTags(map, labelsGold);
            predicted = Tagger.mapLabelsToTags(map, labelsPredicted);
            % Format: <Token> <Predicted> <Gold> <Is unknown>
            for i=1:length(tokens)
                if oovIndices(i)
                    unk = 'U';
                else
                    unk = '';
                end
                fprintf(fid, '%s\t%s\t%s\t%s\n', char(tokens(i)), predicted{i}, gold{i}, unk);
                if ismember(i, sentenceBoundaries)
                    fprintf(fid, '\n');
                end
            end
            fclose(fid);
        end
        
        function [acc, counts] = unknownWordAccuracy(labelsGold, labelsPredicted, oovIndices)
            counts.correct = sum(labelsGold(oovIndices)==labelsPredicted(oovIndices));
            counts.total = sum(oovIndices);
            acc = counts.correct/counts.total;
        end
    end
    
    
    
    
end % classdef